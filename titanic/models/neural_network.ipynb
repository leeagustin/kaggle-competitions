{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (Score: 0.70574)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "MODEL_PARAMS_PATH = 'params/'\n",
    "SUBMISSIONS_PATH = '../submissions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom dataset class for Titanic CSV dataset\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        data = pd.read_csv(path)\n",
    "        self.X = data.drop('Survived', axis=1)\n",
    "        self.y = data['Survived']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [\n",
    "            self.X.loc[idx].values.astype(np.float32),\n",
    "            self.y[idx].astype(np.float32)\n",
    "        ]\n",
    "    \n",
    "    def get_splits(self, n_train=0.8):\n",
    "        train_size = int(0.8 * len(train_data))\n",
    "        valid_size = len(train_data) - train_size\n",
    "        return random_split(train_data, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and validation datasets\n",
    "train_data = TitanicDataset(os.path.join(DATA_PATH + 'preprocessed_train.csv'))\n",
    "train_data, valid_data = train_data.get_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and validation data loaders\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, activation=nn.ReLU):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.layer = nn.Linear(n_inputs, n_outputs)\n",
    "        self.activation = activation()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            DenseLayer(n_inputs, 128),\n",
    "            DenseLayer(128, 64),\n",
    "            DenseLayer(64, 32),\n",
    "            DenseLayer(32, 16),\n",
    "            DenseLayer(16, 1, activation=nn.Sigmoid)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        return X\n",
    "    \n",
    "    def validate(self, dl):\n",
    "        all_preds, all_targets = [], []\n",
    "        for i, (inputs, targets) in enumerate(dl):\n",
    "            preds = model(inputs).reshape(-1, 1).detach().numpy().round()\n",
    "            targets = targets.reshape(-1, 1)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(targets)\n",
    "        all_preds, all_targets = np.vstack(all_preds), np.vstack(all_targets)\n",
    "        acc = accuracy_score(all_targets, all_preds)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/100 Epochs: \n",
      "Loss: 0.4058285\n",
      "Training Accuracy Score: 66.29213483146067%\n",
      "Validation Accuracy Score: 61.452513966480446%\n",
      "\n",
      "20/100 Epochs: \n",
      "Loss: 0.69341767\n",
      "Training Accuracy Score: 60.39325842696629%\n",
      "Validation Accuracy Score: 60.33519553072626%\n",
      "\n",
      "30/100 Epochs: \n",
      "Loss: 0.29570058\n",
      "Training Accuracy Score: 71.20786516853933%\n",
      "Validation Accuracy Score: 64.80446927374301%\n",
      "\n",
      "40/100 Epochs: \n",
      "Loss: 0.61159146\n",
      "Training Accuracy Score: 74.15730337078652%\n",
      "Validation Accuracy Score: 67.0391061452514%\n",
      "\n",
      "50/100 Epochs: \n",
      "Loss: 0.5422526\n",
      "Training Accuracy Score: 74.15730337078652%\n",
      "Validation Accuracy Score: 64.80446927374301%\n",
      "\n",
      "60/100 Epochs: \n",
      "Loss: 0.34001803\n",
      "Training Accuracy Score: 75.28089887640449%\n",
      "Validation Accuracy Score: 68.71508379888269%\n",
      "\n",
      "70/100 Epochs: \n",
      "Loss: 0.7440057\n",
      "Training Accuracy Score: 78.79213483146067%\n",
      "Validation Accuracy Score: 70.94972067039106%\n",
      "\n",
      "80/100 Epochs: \n",
      "Loss: 0.22028174\n",
      "Training Accuracy Score: 76.96629213483146%\n",
      "Validation Accuracy Score: 67.59776536312849%\n",
      "\n",
      "90/100 Epochs: \n",
      "Loss: 0.22023271\n",
      "Training Accuracy Score: 79.21348314606742%\n",
      "Validation Accuracy Score: 72.06703910614524%\n",
      "\n",
      "100/100 Epochs: \n",
      "Loss: 0.15256578\n",
      "Training Accuracy Score: 81.8820224719101%\n",
      "Validation Accuracy Score: 74.86033519553072%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = MLP(10)\n",
    "\n",
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# train/validate model\n",
    "best_model = model\n",
    "lowest_loss = 10000\n",
    "highest_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # train model\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs).squeeze()\n",
    "        loss = criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # validate model\n",
    "    if epoch%10 == 0:\n",
    "        print(str(epoch) + \"/\" + str(epochs)  + \" Epochs: \")\n",
    "        print(\"Loss: \" + str(loss.detach().numpy()))\n",
    "        train_acc = model.validate(train_dl)\n",
    "        valid_acc = model.validate(valid_dl)\n",
    "        print(\"Training Accuracy Score: \" + str(train_acc*100) + \"%\")\n",
    "        print(\"Validation Accuracy Score: \" + str(valid_acc*100) + \"%\\n\")\n",
    "        \n",
    "        if loss < lowest_loss and valid_acc > highest_valid_acc:\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_PARAMS_PATH, 'neural_network.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'preprocessed_test.csv'))\n",
    "test_data = torch.tensor(test_df.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model and \n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PARAMS_PATH, 'neural_network.pt')))\n",
    "model.eval()\n",
    "\n",
    "# predict using test dataset\n",
    "submission = pd.DataFrame()\n",
    "submission['PassengerId'] = test_df['PassengerId']\n",
    "submission['Survived'] = model(test_data).round().int().numpy()\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submission.to_csv(os.path.join(SUBMISSIONS_PATH, 'neural_network.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd06be0ac93fc83aa16398a1f83ff52a1059a5a114c41716045c7d9e7e8b15f1ea5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "6be0ac93fc83aa16398a1f83ff52a1059a5a114c41716045c7d9e7e8b15f1ea5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
